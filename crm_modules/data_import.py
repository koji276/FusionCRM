"""
ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ©Ÿèƒ½ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
fusion_crm_main.pyã‹ã‚‰æŠ½å‡º
"""

import streamlit as st
import pandas as pd
import time
from datetime import datetime
from .data_processor import DataImportProcessor
from .constants import IMPORT_SETTINGS


def show_data_import(company_manager):
    """ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ©Ÿèƒ½ï¼ˆå®Œå…¨å®Ÿè£…ç‰ˆï¼‰"""
    st.header("ğŸ“ ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆ")
    
    tab1, tab2, tab3 = st.tabs(["ğŸ“¤ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", "ğŸ“‹ ã‚¤ãƒ³ãƒãƒ¼ãƒˆå±¥æ­´"])
    
    with tab1:
        st.subheader("ğŸ“¤ ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ")
        st.info("Excel (XLSX)ã€CSVã€TSVãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        uploaded_file = st.file_uploader(
            "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
            type=['xlsx', 'xls', 'csv', 'tsv'],
            help="ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"
        )
        
        if uploaded_file is not None:
            try:
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸå‡¦ç†
                if uploaded_file.name.endswith(('.xlsx', '.xls')):
                    df = pd.read_excel(uploaded_file)
                elif uploaded_file.name.endswith('.csv'):
                    df = pd.read_csv(uploaded_file)
                elif uploaded_file.name.endswith('.tsv'):
                    df = pd.read_csv(uploaded_file, sep='\t')
                
                st.success(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ: {len(df)}è¡Œã®ãƒ‡ãƒ¼ã‚¿")
                
                # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
                st.subheader("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
                st.dataframe(df.head(10), use_container_width=True)
                
                # ã‚«ãƒ©ãƒ ãƒãƒƒãƒ”ãƒ³ã‚°è¨­å®š
                st.subheader("ğŸ”„ ã‚«ãƒ©ãƒ ãƒãƒƒãƒ”ãƒ³ã‚°")
                st.info("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚«ãƒ©ãƒ ã‚’ FusionCRM ã®é …ç›®ã«ãƒãƒƒãƒ”ãƒ³ã‚°ã—ã¦ãã ã•ã„")
                
                # FusionCRMã®æ¨™æº–ã‚«ãƒ©ãƒ 
                fusion_columns = IMPORT_SETTINGS['fusion_columns']
                
                # è‡ªå‹•ãƒãƒƒãƒ”ãƒ³ã‚°ææ¡ˆ
                auto_mapping = DataImportProcessor.suggest_column_mapping(df.columns.tolist())
                
                # ãƒãƒƒãƒ”ãƒ³ã‚°è¨­å®šUI
                mapping = {}
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("**FusionCRMé …ç›®**")
                    for fusion_col, description in fusion_columns.items():
                        st.markdown(f"â€¢ **{description}**")
                
                with col2:
                    st.markdown("**ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚«ãƒ©ãƒ **")
                    for fusion_col, description in fusion_columns.items():
                        suggested = auto_mapping.get(fusion_col, '')
                        options = ['ï¼ˆãƒãƒƒãƒ”ãƒ³ã‚°ã—ãªã„ï¼‰'] + df.columns.tolist()
                        
                        default_index = 0
                        if suggested and suggested in df.columns:
                            default_index = options.index(suggested)
                        
                        selected = st.selectbox(
                            description,
                            options,
                            index=default_index,
                            key=f"mapping_{fusion_col}"
                        )
                        
                        if selected != 'ï¼ˆãƒãƒƒãƒ”ãƒ³ã‚°ã—ãªã„ï¼‰':
                            mapping[fusion_col] = selected
                
                # è©³ç´°è¨­å®š
                st.subheader("âš™ï¸ ã‚¤ãƒ³ãƒãƒ¼ãƒˆè¨­å®š")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    import_mode = st.radio(
                        "ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ¢ãƒ¼ãƒ‰",
                        ["æ–°è¦è¿½åŠ ã®ã¿", "é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹åŸºæº–ï¼‰", "ã™ã¹ã¦è¿½åŠ "]
                    )
                    
                    batch_size = st.number_input(
                        "ãƒãƒƒãƒã‚µã‚¤ã‚º",
                        min_value=1,
                        max_value=100,
                        value=10,
                        help="ä¸€åº¦ã«å‡¦ç†ã™ã‚‹ä¼æ¥­æ•°"
                    )
                
                with col2:
                    auto_wifi_detection = st.checkbox(
                        "WiFiéœ€è¦ã®è‡ªå‹•åˆ¤å®š",
                        value=True,
                        help="ä¼æ¥­åãƒ»èª¬æ˜ã‹ã‚‰WiFiéœ€è¦ã‚’è‡ªå‹•åˆ¤å®š"
                    )
                    
                    auto_picocela_scoring = st.checkbox(
                        "PicoCELAé–¢é€£åº¦ã®è‡ªå‹•è¨ˆç®—",
                        value=True,
                        help="ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°ã«ã‚ˆã‚‹é–¢é€£åº¦è¨ˆç®—"
                    )
                
                # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼å¤‰æ›
                if st.button("ğŸ” å¤‰æ›ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", type="secondary"):
                    if 'company_name' not in mapping:
                        st.error("âŒ ä¼æ¥­åã®ãƒãƒƒãƒ”ãƒ³ã‚°ã¯å¿…é ˆã§ã™")
                    else:
                        preview_df = DataImportProcessor.create_import_preview(df, mapping, auto_wifi_detection, auto_picocela_scoring)
                        st.subheader("ğŸ“‹ å¤‰æ›å¾Œãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆæœ€åˆã®5è¡Œï¼‰")
                        st.dataframe(preview_df.head(), use_container_width=True)
                        
                        # çµ±è¨ˆæƒ…å ±
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            wifi_count = len(preview_df[preview_df['wifi_required'] == 1]) if 'wifi_required' in preview_df.columns else 0
                            st.metric("WiFiéœ€è¦ä¼æ¥­", wifi_count)
                        
                        with col2:
                            high_relevance = len(preview_df[preview_df['picocela_relevance_score'] >= 50]) if 'picocela_relevance_score' in preview_df.columns else 0
                            st.metric("é«˜é–¢é€£åº¦ä¼æ¥­", high_relevance)
                        
                        with col3:
                            total_valid = len(preview_df[preview_df['company_name'].notna() & (preview_df['company_name'] != '')])
                            st.metric("æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿", total_valid)
                
                # ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè¡Œ
                st.subheader("ğŸš€ ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè¡Œ")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    if st.button("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆé–‹å§‹", type="primary", use_container_width=True):
                        if 'company_name' not in mapping:
                            st.error("âŒ ä¼æ¥­åã®ãƒãƒƒãƒ”ãƒ³ã‚°ã¯å¿…é ˆã§ã™")
                        else:
                            execute_data_import(
                                df, mapping, company_manager, 
                                import_mode, batch_size,
                                auto_wifi_detection, auto_picocela_scoring
                            )
                
                with col2:
                    if st.button("ğŸ“„ CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ", type="secondary", use_container_width=True):
                        if 'company_name' in mapping:
                            export_df = DataImportProcessor.create_import_preview(df, mapping, auto_wifi_detection, auto_picocela_scoring)
                            csv = export_df.to_csv(index=False)
                            st.download_button(
                                label="ğŸ“¥ å¤‰æ›å¾Œãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                data=csv,
                                file_name=f"fusioncrm_import_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                                mime="text/csv"
                            )
                        else:
                            st.error("âŒ ã¾ãšä¼æ¥­åã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’è¨­å®šã—ã¦ãã ã•ã„")
                            
            except Exception as e:
                st.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    with tab2:
        st.subheader("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ»æ¤œè¨¼")
        st.info("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ‡ãƒ¼ã‚¿ã®è©³ç´°åˆ†æã‚’è¡Œã„ã¾ã™")
        
        # æ—¢å­˜ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if 'uploaded_file' in locals() and uploaded_file is not None:
            # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯
            DataImportProcessor.show_data_quality_analysis(df)
        else:
            st.info("ğŸ“¤ ã¾ãšãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
    
    with tab3:
        st.subheader("ğŸ“‹ ã‚¤ãƒ³ãƒãƒ¼ãƒˆå±¥æ­´")
        show_import_history()


def execute_data_import(df, mapping, company_manager, import_mode, batch_size, auto_wifi, auto_picocela):
    """ãƒ‡ãƒ¼ã‚¿ã‚¤ãƒ³ãƒãƒ¼ãƒˆã®å®Ÿè¡Œ"""
    
    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã®åˆæœŸåŒ–
    progress_bar = st.progress(0)
    status_text = st.empty()
    stats_container = st.container()
    
    # çµ±è¨ˆæƒ…å ±ã®åˆæœŸåŒ–
    stats = {
        'total': 0,
        'success': 0,
        'failed': 0,
        'skipped': 0,
        'errors': []
    }
    
    # å¤‰æ›å¾Œãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
    import_df = DataImportProcessor.create_import_preview(df, mapping, auto_wifi, auto_picocela)
    total_rows = len(import_df)
    
    if total_rows == 0:
        st.error("âŒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆå¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    status_text.text(f"ğŸ“¥ {total_rows}ç¤¾ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆä¸­...")
    
    # ãƒãƒƒãƒå‡¦ç†ã§ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    for i in range(0, total_rows, batch_size):
        batch_df = import_df.iloc[i:i+batch_size]
        
        for idx, row in batch_df.iterrows():
            try:
                # ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
                company_data = row.to_dict()
                
                # é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹åŸºæº–ï¼‰
                if import_mode == "é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹åŸºæº–ï¼‰" and company_data.get('email'):
                    # æ—¢å­˜ä¼æ¥­ã®ç¢ºèª
                    existing_companies = company_manager.get_all_companies()
                    if not existing_companies.empty and 'email' in existing_companies.columns:
                        if company_data['email'] in existing_companies['email'].values:
                            stats['skipped'] += 1
                            continue
                
                # ä¼æ¥­è¿½åŠ 
                result = company_manager.add_company(company_data, user_id='data_import')
                
                if result:
                    stats['success'] += 1
                else:
                    stats['failed'] += 1
                    stats['errors'].append(f"ä¼æ¥­è¿½åŠ å¤±æ•—: {company_data.get('company_name', 'Unknown')}")
                
                stats['total'] += 1
                
                # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼æ›´æ–°
                progress = (stats['total']) / total_rows
                progress_bar.progress(progress)
                status_text.text(f"ğŸ“¥ å‡¦ç†ä¸­... {stats['total']}/{total_rows} ({stats['success']}æˆåŠŸ, {stats['failed']}å¤±æ•—, {stats['skipped']}ã‚¹ã‚­ãƒƒãƒ—)")
                
            except Exception as e:
                stats['failed'] += 1
                stats['errors'].append(f"ã‚¨ãƒ©ãƒ¼: {str(e)} (ä¼æ¥­: {company_data.get('company_name', 'Unknown')})")
        
        # ãƒãƒƒãƒé–“ã®å°ä¼‘æ­¢
        time.sleep(0.1)
    
    # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    progress_bar.progress(1.0)
    
    if stats['success'] > 0:
        st.success(f"âœ… ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†! {stats['success']}ç¤¾ã‚’æ­£å¸¸ã«è¿½åŠ ã—ã¾ã—ãŸ")
    
    # è©³ç´°çµ±è¨ˆ
    with stats_container:
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("âœ… æˆåŠŸ", stats['success'])
        with col2:
            st.metric("âŒ å¤±æ•—", stats['failed'])
        with col3:
            st.metric("â­ï¸ ã‚¹ã‚­ãƒƒãƒ—", stats['skipped'])
        with col4:
            st.metric("ğŸ“Š å‡¦ç†ç·æ•°", stats['total'])
    
    # ã‚¨ãƒ©ãƒ¼è©³ç´°
    if stats['errors']:
        with st.expander(f"âŒ ã‚¨ãƒ©ãƒ¼è©³ç´° ({len(stats['errors'])}ä»¶)"):
            for error in stats['errors'][:10]:  # æœ€åˆã®10ä»¶ã®ã¿è¡¨ç¤º
                st.text(error)
            if len(stats['errors']) > 10:
                st.text(f"... ãã®ä»– {len(stats['errors']) - 10} ä»¶ã®ã‚¨ãƒ©ãƒ¼")
    
    # ã‚¤ãƒ³ãƒãƒ¼ãƒˆå±¥æ­´ã®ä¿å­˜
    save_import_history(stats, mapping, import_mode)


def save_import_history(stats, mapping, import_mode):
    """ã‚¤ãƒ³ãƒãƒ¼ãƒˆå±¥æ­´ã®ä¿å­˜"""
    if 'import_history' not in st.session_state:
        st.session_state.import_history = []
    
    history_entry = {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'stats': stats,
        'mapping': mapping,
        'import_mode': import_mode
    }
    
    st.session_state.import_history.append(history_entry)


def show_import_history():
    """ã‚¤ãƒ³ãƒãƒ¼ãƒˆå±¥æ­´ã®è¡¨ç¤º"""
    if 'import_history' not in st.session_state or not st.session_state.import_history:
        st.info("ğŸ“‹ ã‚¤ãƒ³ãƒãƒ¼ãƒˆå±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    st.markdown("**ğŸ“Š æœ€è¿‘ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆå±¥æ­´**")
    
    for i, entry in enumerate(reversed(st.session_state.import_history[-10:])):
        with st.expander(f"ğŸ“… {entry['timestamp']} - {entry['stats']['success']}ç¤¾è¿½åŠ "):
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**çµ±è¨ˆæƒ…å ±**")
                st.json(entry['stats'])
            
            with col2:
                st.markdown("**è¨­å®šæƒ…å ±**")
                st.text(f"ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ¢ãƒ¼ãƒ‰: {entry['import_mode']}")
                st.markdown("**ã‚«ãƒ©ãƒ ãƒãƒƒãƒ”ãƒ³ã‚°:**")
                for fusion_col, file_col in entry['mapping'].items():
                    st.text(f"â€¢ {fusion_col} â† {file_col}")
    
    # å±¥æ­´ã‚¯ãƒªã‚¢
    if st.button("ğŸ—‘ï¸ å±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
        st.session_state.import_history = []
        st.rerun()
