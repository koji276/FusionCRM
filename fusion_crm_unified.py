# pages/01_crm_excel.py - ã‚¨ã‚¯ã‚»ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ä»˜ãç‰ˆ
# Updated: 2025-07-29 - Excel upload functionality added
# Complete CRM System with Excel bulk upload feature

import streamlit as st
import pandas as pd
from datetime import datetime
import requests
import json

# ========================================
# ãƒ‡ãƒãƒƒã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
# ========================================
st.error("ğŸš¨ ã‚¨ã‚¯ã‚»ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯¾å¿œç‰ˆ: ä¼æ¥­ä¸€æ‹¬è¿½åŠ æ©Ÿèƒ½ä»˜ã")
st.success("âœ… Excel/CSVä¸€æ‹¬ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ - Google Sheetsé€£æºå®Œå…¨å¯¾å¿œ")

# ========================================
# CRMç®¡ç†ã‚·ã‚¹ãƒ†ãƒ  - ã‚¨ã‚¯ã‚»ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯¾å¿œç‰ˆ
# ========================================

st.title("ğŸ¢ CRMç®¡ç†ã‚·ã‚¹ãƒ†ãƒ  - ã‚¨ã‚¯ã‚»ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯¾å¿œç‰ˆ")
st.caption("ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ç®¡ç†ãƒ»ä¸€æ‹¬ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ»PicoCELAé–¢é€£åº¦åˆ†æãƒ»Google Sheetså®Œå…¨é€£æº")

# Google Sheetsé€£æºæƒ…å ±
st.info("ğŸ”— çµ±åˆãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ãƒ»Google Sheetsã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åŒæœŸ + ã‚¨ã‚¯ã‚»ãƒ«ä¸€æ‹¬ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯¾å¿œ")

# ========================================
# Google Sheets ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆæ—¢å­˜æ©Ÿèƒ½ï¼‰
# ========================================

@st.cache_data(ttl=300)  # 5åˆ†é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥
def get_google_sheets_data():
    """Google Sheetsã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãï¼‰"""
    try:
        api_url = "https://script.google.com/macros/s/AKfycbykUlinwW4oVA08Uo1pqbhHsBWtVM1SMFoo34OMT9kRJ0tRVccsaydlmV5lxjzTrGCu/exec"
        
        response = requests.get(
            api_url,
            params={"action": "get_companies"},
            timeout=20
        )
        
        if response.status_code == 200:
            data = response.json()
            if data.get('success') and data.get('companies'):
                return data['companies'], True
        
        return [], False
        
    except Exception as e:
        st.error(f"Google Sheetsæ¥ç¶šã‚¨ãƒ©ãƒ¼: {str(e)}")
        return [], False

# Google Sheetsãƒ‡ãƒ¼ã‚¿å–å¾—
with st.spinner("ğŸ”„ Google Sheetsã‹ã‚‰ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­..."):
    google_sheets_companies, google_sheets_success = get_google_sheets_data()

if google_sheets_success:
    st.success(f"âœ… Google Sheetsé€£æºæˆåŠŸï¼{len(google_sheets_companies)}ç¤¾ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—")
else:
    st.warning("âš ï¸ Google Sheetsæ¥ç¶šå¤±æ•— - ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œ")

# ========================================
# ã‚¨ã‚¯ã‚»ãƒ«/CSVãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†é–¢æ•°
# ========================================

def process_excel_file(uploaded_file):
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸã‚¨ã‚¯ã‚»ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†"""
    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ãƒã‚§ãƒƒã‚¯
        file_name = uploaded_file.name
        if file_name.endswith('.xlsx') or file_name.endswith('.xls'):
            # ã‚¨ã‚¯ã‚»ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
            df = pd.read_excel(uploaded_file)
        elif file_name.endswith('.csv'):
            # CSVãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
            df = pd.read_csv(uploaded_file, encoding='utf-8')
        else:
            st.error("âŒ ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™ã€‚xlsx, xls, csv ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            return None
        
        st.success(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ: {len(df)}è¡Œã®ãƒ‡ãƒ¼ã‚¿")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®æƒ…å ±è¡¨ç¤º
        st.info(f"ğŸ“Š ã‚«ãƒ©ãƒ æ•°: {len(df.columns)}, è¡Œæ•°: {len(df)}")
        
        # ã‚«ãƒ©ãƒ åã‚’è¡¨ç¤º
        st.write("**ã‚«ãƒ©ãƒ ä¸€è¦§:**", list(df.columns))
        
        return df
        
    except Exception as e:
        st.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None

def normalize_uploaded_data(df):
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’Google Sheetså½¢å¼ã«æ­£è¦åŒ–"""
    normalized_companies = []
    
    # ã‚«ãƒ©ãƒ åã®ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆæŸ”è»Ÿãªå¯¾å¿œï¼‰
    column_mapping = {
        # ä¼æ¥­å
        'company_name': ['Company Name', 'company_name', 'ä¼æ¥­å', 'ä¼šç¤¾å', 'name'],
        # ãƒ¡ãƒ¼ãƒ«
        'email': ['Email Address', 'email', 'Email', 'ãƒ¡ãƒ¼ãƒ«', 'ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹'],
        # ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆ
        'website': ['Website', 'website', 'URL', 'ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆ', 'ã‚µã‚¤ãƒˆ'],
        # é›»è©±
        'phone': ['Phone', 'phone', 'Tel', 'TEL', 'é›»è©±', 'é›»è©±ç•ªå·'],
        # ä½æ‰€
        'address': ['Address', 'address', 'ä½æ‰€', 'æ‰€åœ¨åœ°'],
        # WiFiéœ€è¦
        'wifi_needs': ['Needs Wi-Fi', 'wifi_needs', 'WiFiéœ€è¦', 'WiFi', 'wifi'],
        # èª¬æ˜
        'description': ['Description', 'description', 'èª¬æ˜', 'æ¦‚è¦', 'notes'],
        # é€£çµ¡å…ˆ
        'contact': ['Contact Info', 'contact', 'é€£çµ¡å…ˆ', 'æ‹…å½“è€…'],
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°
        'keyword_count': ['Keyword Match Count', 'keyword_count', 'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°']
    }
    
    # å®Ÿéš›ã®ã‚«ãƒ©ãƒ åã‚’ç‰¹å®š
    actual_columns = {}
    for field, possible_names in column_mapping.items():
        for col_name in df.columns:
            if col_name in possible_names:
                actual_columns[field] = col_name
                break
    
    st.write("**æ¤œå‡ºã•ã‚ŒãŸã‚«ãƒ©ãƒ ãƒãƒƒãƒ”ãƒ³ã‚°:**")
    for field, col_name in actual_columns.items():
        st.write(f"â€¢ {field}: `{col_name}`")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–
    for idx, row in df.iterrows():
        try:
            # WiFiéœ€è¦ã®åˆ¤å®š
            wifi_needs_value = str(row.get(actual_columns.get('wifi_needs', ''), '')).lower()
            if wifi_needs_value in ['yes', 'true', '1', 'high', 'medium']:
                wifi_needs = 'High' if wifi_needs_value in ['yes', 'true', '1'] else wifi_needs_value.title()
            else:
                wifi_needs = 'Low'
            
            # PicoCELAã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°ãƒ™ãƒ¼ã‚¹ï¼‰
            keyword_count = row.get(actual_columns.get('keyword_count', ''), 0)
            try:
                keyword_count = int(keyword_count) if keyword_count else 0
            except:
                keyword_count = 0
            
            # åŸºæœ¬ã‚¹ã‚³ã‚¢è¨ˆç®—
            picocela_score = min(keyword_count * 10 + (30 if wifi_needs != 'Low' else 0), 100)
            
            # æ­£è¦åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿
            normalized_company = {
                'company_id': f"UPLOAD_{datetime.now().strftime('%Y%m%d')}_{idx+1:03d}",
                'company_name': str(row.get(actual_columns.get('company_name', ''), f'Company_{idx+1}')),
                'email': str(row.get(actual_columns.get('email', ''), '')),
                'phone': str(row.get(actual_columns.get('phone', ''), '')),
                'website': str(row.get(actual_columns.get('website', ''), '')),
                'description': str(row.get(actual_columns.get('description', ''), ''))[:500],  # 500æ–‡å­—åˆ¶é™
                'wifi_needs': wifi_needs,
                'picoCELA_relevance': picocela_score,
                'priority_score': min(picocela_score + 10, 100),
                'sales_status': 'New',
                'created_at': datetime.now().isoformat(),
                'updated_at': datetime.now().isoformat(),
                'tags': 'uploaded',
                'contact_name': str(row.get(actual_columns.get('contact', ''), '')),
                'address': str(row.get(actual_columns.get('address', ''), '')),
                'keyword_count': keyword_count
            }
            
            normalized_companies.append(normalized_company)
            
        except Exception as e:
            st.warning(f"âš ï¸ è¡Œ {idx+1} ã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
            continue
    
    return normalized_companies

def normalize_companies_data(companies):
    """æ—¢å­˜ã®Google Sheetsãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–é–¢æ•°"""
    normalized = []
    
    for company in companies:
        # WiFiéœ€è¦ã®è¡¨ç¤ºå¤‰æ›
        wifi_needs = str(company.get('wifi_needs', '')).lower()
        if wifi_needs == 'high':
            wifi_display = 'âœ… é«˜éœ€è¦'
        elif wifi_needs == 'medium':
            wifi_display = 'âœ… ä¸­éœ€è¦' 
        elif wifi_needs == 'low':
            wifi_display = 'âš ï¸ ä½éœ€è¦'
        else:
            wifi_display = 'â“ æœªç¢ºèª'
        
        # æ¥­ç•Œã®æ¨å®š
        description = str(company.get('description', '')).lower()
        if 'construction' in description or 'building' in description:
            industry = 'å»ºè¨­æ¥­'
        elif 'manufacturing' in description or 'factory' in description:
            industry = 'è£½é€ æ¥­'
        elif 'software' in description or 'ai' in description or 'platform' in description:
            industry = 'ITãƒ»ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢'
        elif 'wifi' in description or 'wireless' in description or 'network' in description:
            industry = 'ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ»é€šä¿¡'
        else:
            industry = 'ãã®ä»–'
        
        normalized_company = {
            'ID': company.get('company_id', f"ID_{len(normalized)+1}"),
            'ä¼æ¥­å': company.get('company_name', 'N/A'),
            'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹': company.get('sales_status', 'New'),
            'PicoCELAã‚¹ã‚³ã‚¢': int(company.get('picoCELA_relevance', 0)) if company.get('picoCELA_relevance') else 0,
            'WiFiéœ€è¦': wifi_display,
            'è²©å£²å“¡': 'admin',
            'ãƒ¡ãƒ¼ãƒ«': company.get('email', ''),
            'æ¥­ç•Œ': industry,
            'ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆ': company.get('website_url') or company.get('website', ''),
            'é›»è©±ç•ªå·': company.get('phone', ''),
            'é€£çµ¡å…ˆ': company.get('contact_name', ''),
            'å‚™è€ƒ': company.get('description', '')[:150] + '...' if len(str(company.get('description', ''))) > 150 else company.get('description', ''),
            'ç™»éŒ²æ—¥': company.get('created_at', '')[:10] if company.get('created_at') else datetime.now().strftime('%Y-%m-%d'),
            'æ›´æ–°æ—¥': company.get('updated_at', '')[:10] if company.get('updated_at') else '',
            'å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢': int(company.get('priority_score', 0)) if company.get('priority_score') else 0,
            'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°': company.get('keyword_count', 0)
        }
        
        normalized.append(normalized_company)
    
    return normalized

# ========================================
# ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æ±ºå®š
# ========================================

if google_sheets_success and google_sheets_companies:
    companies_data = normalize_companies_data(google_sheets_companies)
    data_source = f"Google Sheets ({len(companies_data)}ç¤¾)"
else:
    companies_data = []
    data_source = "ãƒ‡ãƒ¼ã‚¿ãªã—"

# ========================================
# ã‚¿ãƒ–ä½œæˆãƒ»æ©Ÿèƒ½å®Ÿè£…
# ========================================

tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸ“Š ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰", 
    "ğŸ¢ ä¼æ¥­ç®¡ç†", 
    "ğŸ“ˆ åˆ†æ", 
    "ğŸ“¤ ä¸€æ‹¬ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", 
    "âš™ï¸ è¨­å®š"
])

with tab1:
    # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼ˆæ—¢å­˜æ©Ÿèƒ½ï¼‰
    st.header("ğŸ“Š CRMãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
    st.caption(f"ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: {data_source}")
    
    if companies_data:
        # çµ±è¨ˆãƒ¡ãƒˆãƒªã‚¯ã‚¹
        total_companies = len(companies_data)
        wifi_any_need = len([c for c in companies_data if 'âœ…' in str(c.get('WiFiéœ€è¦', ''))])
        high_score = len([c for c in companies_data if int(c.get('PicoCELAã‚¹ã‚³ã‚¢', 0)) >= 50])
        qualified = len([c for c in companies_data if c.get('ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹') in ['Qualified', 'Engaged', 'Proposal']])
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ğŸ“ˆ ç·ä¼æ¥­æ•°", total_companies)
        with col2:
            wifi_rate = (wifi_any_need / total_companies * 100) if total_companies > 0 else 0
            st.metric("ğŸ“¶ WiFiéœ€è¦ä¼æ¥­", f"{wifi_any_need} ({wifi_rate:.1f}%)")
        with col3:
            score_rate = (high_score / total_companies * 100) if total_companies > 0 else 0
            st.metric("ğŸ¯ é«˜ã‚¹ã‚³ã‚¢ä¼æ¥­", f"{high_score} ({score_rate:.1f}%)")
        with col4:
            qualified_rate = (qualified / total_companies * 100) if total_companies > 0 else 0
            st.metric("ğŸ’¼ æœ‰æœ›ä¼æ¥­", f"{qualified} ({qualified_rate:.1f}%)")
        
        # ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ä¸€è¦§
        st.subheader("ğŸ“‹ ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ä¸€è¦§")
        display_data = []
        for company in companies_data:
            display_data.append({
                'ä¼æ¥­å': company['ä¼æ¥­å'],
                'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹': company['ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'],
                'PicoCELAã‚¹ã‚³ã‚¢': company['PicoCELAã‚¹ã‚³ã‚¢'],
                'WiFiéœ€è¦': company['WiFiéœ€è¦'],
                'æ¥­ç•Œ': company['æ¥­ç•Œ'],
                'ãƒ¡ãƒ¼ãƒ«': company['ãƒ¡ãƒ¼ãƒ«'],
                'ç™»éŒ²æ—¥': company['ç™»éŒ²æ—¥']
            })
        
        display_df = pd.DataFrame(display_data)
        st.dataframe(display_df, use_container_width=True)
    else:
        st.warning("ğŸ“‹ ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ä¸€æ‹¬ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¿ãƒ–ã‹ã‚‰ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")

with tab2:
    # ä¼æ¥­ç®¡ç†ï¼ˆæ—¢å­˜æ©Ÿèƒ½ï¼‰
    st.header("ğŸ¢ ä¼æ¥­ç®¡ç†")
    
    if companies_data:
        # æ¤œç´¢ãƒ»ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        col1, col2 = st.columns(2)
        
        with col1:
            search_term = st.text_input("ğŸ” ä¼æ¥­åæ¤œç´¢", key="search_companies")
        
        with col2:
            status_list = ["å…¨ã¦"] + sorted(list(set([c.get('ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', '') for c in companies_data if c.get('ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹')])))
            selected_status = st.selectbox("ğŸ“Š ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼", status_list, key="filter_status")
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        filtered_companies = companies_data.copy()
        
        if search_term:
            filtered_companies = [c for c in filtered_companies 
                                if search_term.lower() in c.get('ä¼æ¥­å', '').lower()]
        
        if selected_status != "å…¨ã¦":
            filtered_companies = [c for c in filtered_companies 
                                if c.get('ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹') == selected_status]
        
        st.subheader(f"ğŸ“‹ æ¤œç´¢çµæœ ({len(filtered_companies)}ç¤¾)")
        
        if filtered_companies:
            for company in filtered_companies:
                with st.expander(f"ğŸ¢ {company['ä¼æ¥­å']} - {company['ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹']} (ã‚¹ã‚³ã‚¢: {company['PicoCELAã‚¹ã‚³ã‚¢']})"):
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.write(f"**ID**: {company['ID']}")
                        st.write(f"**ä¼æ¥­å**: {company['ä¼æ¥­å']}")
                        st.write(f"**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: {company['ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹']}")
                        st.write(f"**æ¥­ç•Œ**: {company['æ¥­ç•Œ']}")
                    
                    with col2:
                        st.write(f"**PicoCELAã‚¹ã‚³ã‚¢**: {company['PicoCELAã‚¹ã‚³ã‚¢']}")
                        st.write(f"**å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢**: {company['å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢']}")
                        st.write(f"**WiFiéœ€è¦**: {company['WiFiéœ€è¦']}")
                        st.write(f"**ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°**: {company.get('ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°', 'N/A')}")
                    
                    with col3:
                        st.write(f"**ãƒ¡ãƒ¼ãƒ«**: {company['ãƒ¡ãƒ¼ãƒ«']}")
                        st.write(f"**é›»è©±**: {company['é›»è©±ç•ªå·']}")
                        st.write(f"**é€£çµ¡å…ˆ**: {company['é€£çµ¡å…ˆ']}")
                        st.write(f"**ç™»éŒ²æ—¥**: {company['ç™»éŒ²æ—¥']}")
                    
                    if company.get('å‚™è€ƒ'):
                        st.write(f"**å‚™è€ƒ**: {company['å‚™è€ƒ']}")
        else:
            st.info("æ¤œç´¢æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ä¼æ¥­ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        st.warning("ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

with tab3:
    # åˆ†æï¼ˆæ—¢å­˜æ©Ÿèƒ½ï¼‰
    st.header("ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿åˆ†æ")
    
    if companies_data:
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ†å¸ƒ
        st.subheader("ğŸ“Š ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ†å¸ƒ")
        status_counts = {}
        for company in companies_data:
            status = company.get('ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹', 'Unknown')
            status_counts[status] = status_counts.get(status, 0) + 1
        
        if status_counts:
            st.bar_chart(status_counts)
        
        # PicoCELAã‚¹ã‚³ã‚¢åˆ†æ
        st.subheader("ğŸ¯ PicoCELAã‚¹ã‚³ã‚¢åˆ†æ")
        scores = [int(c.get('PicoCELAã‚¹ã‚³ã‚¢', 0)) for c in companies_data]
        
        if scores:
            score_ranges = {
                '0-25ç‚¹': len([s for s in scores if 0 <= s <= 25]),
                '26-50ç‚¹': len([s for s in scores if 26 <= s <= 50]),
                '51-75ç‚¹': len([s for s in scores if 51 <= s <= 75]),
                '76-100ç‚¹': len([s for s in scores if 76 <= s <= 100])
            }
            
            st.bar_chart(score_ranges)
            
            # çµ±è¨ˆæƒ…å ±
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("å¹³å‡ã‚¹ã‚³ã‚¢", f"{sum(scores)/len(scores):.1f}ç‚¹")
            with col2:
                st.metric("æœ€é«˜ã‚¹ã‚³ã‚¢", f"{max(scores)}ç‚¹")
            with col3:
                st.metric("æœ€ä½ã‚¹ã‚³ã‚¢", f"{min(scores)}ç‚¹")
        
        # WiFiéœ€è¦åˆ†æ
        st.subheader("ğŸ“¶ WiFiéœ€è¦åˆ†æ")
        wifi_counts = {}
        for company in companies_data:
            wifi_need = company.get('WiFiéœ€è¦', 'â“ æœªç¢ºèª')
            wifi_counts[wifi_need] = wifi_counts.get(wifi_need, 0) + 1
        
        if wifi_counts:
            st.bar_chart(wifi_counts)
    else:
        st.warning("åˆ†æã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

with tab4:
    # ä¸€æ‹¬ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ï¼ˆæ–°æ©Ÿèƒ½ï¼‰
    st.header("ğŸ“¤ ä¸€æ‹¬ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    st.info("ğŸ’¡ ã‚¨ã‚¯ã‚»ãƒ«/CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ‹¬ã§è¿½åŠ ã§ãã¾ã™")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    uploaded_file = st.file_uploader(
        "ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
        type=['xlsx', 'xls', 'csv'],
        help="å¯¾å¿œå½¢å¼: Excel (.xlsx, .xls), CSV (.csv)"
    )
    
    if uploaded_file is not None:
        st.success(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠã•ã‚Œã¾ã—ãŸ: {uploaded_file.name}")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
        df = process_excel_file(uploaded_file)
        
        if df is not None:
            # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
            st.subheader("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
            st.dataframe(df.head(10), use_container_width=True)
            
            # ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–
            with st.spinner("ğŸ”„ ãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–ä¸­..."):
                normalized_data = normalize_uploaded_data(df)
            
            if normalized_data:
                st.success(f"âœ… {len(normalized_data)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–å®Œäº†")
                
                # æ­£è¦åŒ–çµæœã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
                st.subheader("ğŸ”„ æ­£è¦åŒ–çµæœãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
                preview_data = []
                for company in normalized_data[:5]:  # æœ€åˆã®5ä»¶
                    preview_data.append({
                        'ä¼æ¥­å': company['company_name'],
                        'ãƒ¡ãƒ¼ãƒ«': company['email'],
                        'WiFiéœ€è¦': company['wifi_needs'],
                        'PicoCELAã‚¹ã‚³ã‚¢': company['picoCELA_relevance'],
                        'ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°': company.get('keyword_count', 0)
                    })
                
                preview_df = pd.DataFrame(preview_data)
                st.dataframe(preview_df, use_container_width=True)
                
                # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç¢ºèª
                st.subheader("ğŸš€ Google Sheetsã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
                st.warning("âš ï¸ æ³¨æ„: ã“ã®æ©Ÿèƒ½ã¯å°†æ¥å®Ÿè£…äºˆå®šã§ã™ã€‚ç¾åœ¨ã¯ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã¿è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    if st.button("ğŸ“Š CSVã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ", key="export_normalized"):
                        # æ­£è¦åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’CSVã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                        export_df = pd.DataFrame(normalized_data)
                        csv_data = export_df.to_csv(index=False, encoding='utf-8-sig')
                        
                        st.download_button(
                            label="ğŸ’¾ æ­£è¦åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                            data=csv_data,
                            file_name=f'normalized_companies_{datetime.now().strftime("%Y%m%d_%H%M")}.csv',
                            mime='text/csv'
                        )
                
                with col2:
                    st.info("ğŸ”® å°†æ¥å®Ÿè£…äºˆå®š:\n- Google Sheetsã¸ã®ç›´æ¥ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n- é‡è¤‡ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½\n- ãƒãƒƒãƒå‡¦ç†çŠ¶æ³è¡¨ç¤º")
            else:
                st.error("âŒ ãƒ‡ãƒ¼ã‚¿ã®æ­£è¦åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    
    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å½¢å¼ã®èª¬æ˜
    st.subheader("ğŸ“ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å½¢å¼ã®èª¬æ˜")
    
    with st.expander("ğŸ“‹ å¯¾å¿œã™ã‚‹ã‚«ãƒ©ãƒ å"):
        st.write("""
        **è‡ªå‹•èªè­˜ã•ã‚Œã‚‹ã‚«ãƒ©ãƒ åï¼ˆå¤§æ–‡å­—å°æ–‡å­—å•ã‚ãšï¼‰:**
        
        - **ä¼æ¥­å**: Company Name, company_name, ä¼æ¥­å, ä¼šç¤¾å, name
        - **ãƒ¡ãƒ¼ãƒ«**: Email Address, email, Email, ãƒ¡ãƒ¼ãƒ«, ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹
        - **ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆ**: Website, website, URL, ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆ, ã‚µã‚¤ãƒˆ
        - **é›»è©±**: Phone, phone, Tel, TEL, é›»è©±, é›»è©±ç•ªå·
        - **ä½æ‰€**: Address, address, ä½æ‰€, æ‰€åœ¨åœ°
        - **WiFiéœ€è¦**: Needs Wi-Fi, wifi_needs, WiFiéœ€è¦, WiFi, wifi
        - **èª¬æ˜**: Description, description, èª¬æ˜, æ¦‚è¦, notes
        - **é€£çµ¡å…ˆ**: Contact Info, contact, é€£çµ¡å…ˆ, æ‹…å½“è€…
        - **ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°**: Keyword Match Count, keyword_count, ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°
        """)
    
    with st.expander("ğŸ’¡ ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿å½¢å¼"):
        sample_data = {
            'Company Name': ['Sample Corp', 'Test Industries'],
            'Email Address': ['info@sample.com', 'contact@test.com'],
            'Website': ['https://sample.com', 'https://test.com'],
            'Phone': ['123-456-7890', '098-765-4321'],
            'Needs Wi-Fi': ['Yes', 'No'],
            'Description': ['Sample description', 'Test company description'],
            'Keyword Match Count': [5, 3]
        }
        sample_df = pd.DataFrame(sample_data)
        st.dataframe(sample_df, use_container_width=True)

with tab5:
    # ã‚·ã‚¹ãƒ†ãƒ è¨­å®šï¼ˆæ—¢å­˜æ©Ÿèƒ½ï¼‰
    st.header("âš™ï¸ ã‚·ã‚¹ãƒ†ãƒ è¨­å®š")
    
    # æ¥ç¶šçŠ¶æ³
    st.subheader("ğŸ”— APIæ¥ç¶šçŠ¶æ³")
    col1, col2 = st.columns(2)
    
    with col1:
        if google_sheets_success:
            st.success("âœ… Google Sheets APIæ¥ç¶šæ­£å¸¸")
        else:
            st.error("âŒ Google Sheets APIæ¥ç¶šå¤±æ•—")
    
    with col2:
        st.metric("ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹", "Google Sheets" if google_sheets_success else "ã‚ªãƒ•ãƒ©ã‚¤ãƒ³")
    
    # ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆ
    st.subheader("ğŸ“Š ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆ")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ç·ä¼æ¥­æ•°", len(companies_data))
    with col2:
        high_priority = len([c for c in companies_data if int(c.get('å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢', 0)) >= 50])
        st.metric("é«˜å„ªå…ˆåº¦ä¼æ¥­", high_priority)
    with col3:
        st.metric("æœ€çµ‚æ›´æ–°", datetime.now().strftime("%H:%M"))
    with col4:
        st.metric("ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹", "æ­£å¸¸å‹•ä½œ")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    st.subheader("ğŸ“¤ ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
    if companies_data and st.button("ğŸ“Š å…¨ãƒ‡ãƒ¼ã‚¿CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ", key="export_all_csv"):
        df = pd.DataFrame(companies_data)
        csv = df.to_csv(index=False, encoding='utf-8-sig')
        
        st.download_button(
            label="ğŸ’¾ å…¨ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv,
            file_name=f'fusioncrm_all_companies_{datetime.now().strftime("%Y%m%d_%H%M")}.csv',
            mime='text/csv'
        )
        st.success("âœ… CSVãƒ•ã‚¡ã‚¤ãƒ«ã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    
    # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
    st.subheader("ğŸ” ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
    st.info("**æ–°æ©Ÿèƒ½**: ã‚¨ã‚¯ã‚»ãƒ«/CSVä¸€æ‹¬ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯¾å¿œ")
    st.info("**å¯¾å¿œå½¢å¼**: .xlsx, .xls, .csv")
    st.info("**è‡ªå‹•æ©Ÿèƒ½**: ã‚«ãƒ©ãƒ åè‡ªå‹•èªè­˜ã€PicoCELAã‚¹ã‚³ã‚¢è‡ªå‹•è¨ˆç®—ã€WiFiéœ€è¦åˆ¤å®š")
