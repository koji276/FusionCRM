# pages/01_crm_debug.py - ãƒ‡ãƒ¼ã‚¿æ§‹é€ ãƒ‡ãƒãƒƒã‚°ç‰ˆ
# Updated: 2025-07-29 - Debug actual Google Sheets data structure
# Complete data structure analysis

import streamlit as st
import pandas as pd
from datetime import datetime
import requests
import json

# ========================================
# ãƒ‡ãƒãƒƒã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
# ========================================
st.error("ğŸš¨ ãƒ‡ãƒãƒƒã‚°ç‰ˆ: Google Sheetsã®å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’è©³ç´°åˆ†æ")
st.success("âœ… ãƒ‡ãƒ¼ã‚¿æ§‹é€ å®Œå…¨è§£æç‰ˆ")

# ========================================
# CRMç®¡ç†ã‚·ã‚¹ãƒ†ãƒ  - ãƒ‡ãƒãƒƒã‚°ç‰ˆ
# ========================================

st.title("ğŸ¢ CRMç®¡ç†ã‚·ã‚¹ãƒ†ãƒ  - ãƒ‡ãƒãƒƒã‚°ç‰ˆ")
st.caption("Google Sheetsãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®å®Œå…¨è§£æ")

# ========================================
# Google Sheets ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»è©³ç´°åˆ†æ
# ========================================

st.header("ğŸ” Google Sheetsãƒ‡ãƒ¼ã‚¿æ§‹é€ è§£æ")

try:
    st.info("ğŸ”„ Google Sheetsã‹ã‚‰ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
    
    # Google Apps Script URL
    api_url = "https://script.google.com/macros/s/AKfycbykUlinwW4oVA08Uo1pqbhHsBWtVM1SMFoo34OMT9kRJ0tRVccsaydlmV5lxjzTrGCu/exec"
    
    # APIãƒªã‚¯ã‚¨ã‚¹ãƒˆå®Ÿè¡Œ
    response = requests.get(
        api_url,
        params={"action": "get_companies"},
        timeout=20
    )
    
    st.info(f"ğŸ“¡ API Response Status: {response.status_code}")
    
    if response.status_code == 200:
        # ç”Ÿã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤º
        st.subheader("ğŸ“„ ç”Ÿã®APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆæœ€åˆã®1000æ–‡å­—ï¼‰")
        raw_text = response.text
        st.text(raw_text[:1000] + "..." if len(raw_text) > 1000 else raw_text)
        
        try:
            data = response.json()
            
            # JSONã®åŸºæœ¬æ§‹é€ ã‚’è¡¨ç¤º
            st.subheader("ğŸ“Š JSONåŸºæœ¬æ§‹é€ ")
            st.write(f"success: {data.get('success')}")
            st.write(f"data exists: {bool(data.get('data'))}")
            st.write(f"data type: {type(data.get('data'))}")
            st.write(f"data length: {len(data.get('data', []))}")
            
            if data.get('success') and data.get('data'):
                companies = data['data']
                
                # æœ€åˆã®ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ã®å®Œå…¨æ§‹é€ ã‚’è¡¨ç¤º
                st.subheader("ğŸ¢ æœ€åˆã®ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ã®å®Œå…¨æ§‹é€ ")
                if companies:
                    first_company = companies[0]
                    st.write("**å…¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ä¸€è¦§:**")
                    
                    for key, value in first_company.items():
                        st.write(f"â€¢ **{key}**: `{type(value).__name__}` = {str(value)[:100]}{'...' if len(str(value)) > 100 else ''}")
                    
                    # JSONã¨ã—ã¦æ•´å½¢è¡¨ç¤º
                    st.subheader("ğŸ“‹ æœ€åˆã®ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ï¼ˆJSONå½¢å¼ï¼‰")
                    st.json(first_company)
                    
                    # 2ç•ªç›®ã®ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ã‚‚è¡¨ç¤ºï¼ˆæ¯”è¼ƒç”¨ï¼‰
                    if len(companies) > 1:
                        st.subheader("ğŸ¢ 2ç•ªç›®ã®ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ï¼ˆæ¯”è¼ƒç”¨ï¼‰")
                        second_company = companies[1]
                        st.json(second_company)
                
                # å…¨ä¼æ¥­ã®ã‚­ãƒ¼ä¸€è¦§ã‚’åé›†
                st.subheader("ğŸ”‘ å…¨ä¼æ¥­ã§ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã‚­ãƒ¼ä¸€è¦§")
                all_keys = set()
                for company in companies:
                    all_keys.update(company.keys())
                
                sorted_keys = sorted(list(all_keys))
                st.write(f"**ç·ã‚­ãƒ¼æ•°**: {len(sorted_keys)}")
                
                for i, key in enumerate(sorted_keys):
                    # å„ã‚­ãƒ¼ãŒã©ã‚Œã ã‘ã®ä¼æ¥­ã§ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã‹ã‚«ã‚¦ãƒ³ãƒˆ
                    usage_count = sum(1 for company in companies if key in company and company[key] is not None and str(company[key]).strip() != '')
                    st.write(f"{i+1:2d}. **{key}** - ä½¿ç”¨ä¼æ¥­æ•°: {usage_count}/{len(companies)}")
                
                # ãƒ‡ãƒ¼ã‚¿å‹åˆ†æ
                st.subheader("ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿å‹åˆ†æ")
                key_types = {}
                for company in companies:
                    for key, value in company.items():
                        if key not in key_types:
                            key_types[key] = set()
                        key_types[key].add(type(value).__name__)
                
                for key, types in sorted(key_types.items()):
                    st.write(f"â€¢ **{key}**: {', '.join(types)}")
                
                # ã‚µãƒ³ãƒ—ãƒ«å€¤è¡¨ç¤º
                st.subheader("ğŸ’¼ å„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ã‚µãƒ³ãƒ—ãƒ«å€¤")
                for key in sorted_keys[:10]:  # æœ€åˆã®10å€‹ã®ã‚­ãƒ¼
                    sample_values = []
                    for company in companies[:3]:  # æœ€åˆã®3ç¤¾
                        if key in company and company[key] is not None:
                            value = str(company[key])[:50] + ('...' if len(str(company[key])) > 50 else '')
                            sample_values.append(value)
                    
                    if sample_values:
                        st.write(f"**{key}**: {' | '.join(sample_values)}")
                
                # ========================================
                # ç°¡æ˜“ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼ˆç¾åœ¨ã®ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
                # ========================================
                
                st.header("ğŸ“Š ç¾åœ¨ã®ãƒ­ã‚¸ãƒƒã‚¯ã§ã®ç°¡æ˜“ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
                
                # ç¾åœ¨ã®æ­£è¦åŒ–ãƒ­ã‚¸ãƒƒã‚¯ã‚’é©ç”¨
                normalized_companies = []
                for company in companies:
                    normalized = {
                        'ID': company.get('company_id') or company.get('ID') or f"ID_{len(normalized_companies)+1}",
                        'ä¼æ¥­å': company.get('company_name') or company.get('ä¼æ¥­å') or 'N/A',
                        'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹': company.get('sales_status') or company.get('ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹') or 'New',
                        'PicoCELAã‚¹ã‚³ã‚¢': company.get('picoCELA_relevance') or company.get('PicoCELAã‚¹ã‚³ã‚¢') or 0,
                        'WiFiéœ€è¦': company.get('wifi_needs') or company.get('WiFiéœ€è¦') or 'Unknown',
                        'ãƒ¡ãƒ¼ãƒ«': company.get('email') or company.get('ãƒ¡ãƒ¼ãƒ«') or '',
                        'å‚™è€ƒ': company.get('description') or company.get('å‚™è€ƒ') or ''
                    }
                    normalized_companies.append(normalized)
                
                # æ­£è¦åŒ–çµæœè¡¨ç¤º
                st.subheader("ğŸ”„ æ­£è¦åŒ–å¾Œã®ãƒ‡ãƒ¼ã‚¿")
                for i, company in enumerate(normalized_companies[:3]):
                    st.write(f"**ä¼æ¥­ {i+1}:**")
                    for key, value in company.items():
                        st.write(f"  â€¢ {key}: {value}")
                    st.write("---")
                
                # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ è¡¨ç¤º
                if normalized_companies:
                    st.subheader("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ è¡¨ç¤º")
                    df = pd.DataFrame(normalized_companies)
                    st.dataframe(df, use_container_width=True)
                
                google_sheets_success = True
                
            else:
                st.error("âŒ ãƒ‡ãƒ¼ã‚¿ã® 'success' ãƒ•ãƒ©ã‚°ãŒ False ã¾ãŸã¯ 'data' ãŒç©ºã§ã™")
                st.json(data)
                google_sheets_success = False
                
        except json.JSONDecodeError as e:
            st.error(f"âŒ JSONè§£æã‚¨ãƒ©ãƒ¼: {str(e)}")
            st.text("Raw response:")
            st.text(response.text[:500])
            google_sheets_success = False
            
    else:
        st.error(f"âŒ HTTP Error: {response.status_code}")
        st.text(f"Response: {response.text}")
        google_sheets_success = False

except Exception as e:
    st.error(f"âŒ æ¥ç¶šã‚¨ãƒ©ãƒ¼: {str(e)}")
    google_sheets_success = False

# ========================================
# æ¨å¥¨ã•ã‚Œã‚‹ä¿®æ­£æ¡ˆ
# ========================================

st.header("ğŸ’¡ æ¨å¥¨ã•ã‚Œã‚‹ä¿®æ­£æ¡ˆ")

if google_sheets_success:
    st.success("âœ… Google Sheetsæ¥ç¶šæˆåŠŸï¼ä¸Šè¨˜ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ åˆ†æã‚’åŸºã«æ­£ç¢ºãªæ­£è¦åŒ–ãƒ­ã‚¸ãƒƒã‚¯ã‚’ä½œæˆã§ãã¾ã™ã€‚")
    
    st.info("""
    **æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:**
    1. ä¸Šè¨˜ã®ã€Œå…¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ä¸€è¦§ã€ã‚’ç¢ºèª
    2. å®Ÿéš›ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã‚­ãƒ¼åã‚’ç‰¹å®š
    3. ãƒ‡ãƒ¼ã‚¿å‹ã‚’ç¢ºèª
    4. æ­£è¦åŒ–ãƒ­ã‚¸ãƒƒã‚¯ã‚’ä¿®æ­£
    """)
    
else:
    st.error("âŒ Google Sheetsæ¥ç¶šå¤±æ•—ã€‚APIè¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

# ========================================
# ã‚­ãƒ¼åãƒãƒƒãƒ”ãƒ³ã‚°æ¨æ¸¬
# ========================================

st.header("ğŸ” æ¨æ¸¬ã•ã‚Œã‚‹ã‚­ãƒ¼åãƒãƒƒãƒ”ãƒ³ã‚°")

expected_mappings = {
    "ä¼æ¥­å": ["company_name", "name", "ä¼æ¥­å", "ä¼šç¤¾å"],
    "ãƒ¡ãƒ¼ãƒ«": ["email", "mail", "ãƒ¡ãƒ¼ãƒ«", "ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹"],
    "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": ["sales_status", "status", "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", "çŠ¶æ…‹"],
    "PicoCELAã‚¹ã‚³ã‚¢": ["picoCELA_relevance", "picocela_relevance", "relevance", "score", "ã‚¹ã‚³ã‚¢"],
    "WiFiéœ€è¦": ["wifi_needs", "wifi_requirement", "WiFiéœ€è¦", "éœ€è¦"],
    "æ¥­ç•Œ": ["industry", "sector", "æ¥­ç•Œ", "åˆ†é‡"],
    "ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆ": ["website", "website_url", "url", "ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆ"],
    "å‚™è€ƒ": ["description", "notes", "memo", "å‚™è€ƒ", "èª¬æ˜"]
}

for japanese_key, possible_keys in expected_mappings.items():
    st.write(f"**{japanese_key}**: {' ã¾ãŸã¯ '.join(possible_keys)}")

st.info("ä¸Šè¨˜ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ åˆ†æçµæœã¨ç…§ã‚‰ã—åˆã‚ã›ã¦ã€æ­£ç¢ºãªã‚­ãƒ¼åã‚’ç‰¹å®šã—ã¦ãã ã•ã„ã€‚")
